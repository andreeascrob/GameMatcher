{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762cf4cb-d833-4c95-a912-c40f004e6fb3",
   "metadata": {},
   "source": [
    "# Solution to Exercise 08 - Web Scraping\n",
    "\n",
    "In today's exercise we're using the Python libraries *BeautifulSoup* and *owlready2* to create an ontology from data scraped from the Web.\n",
    "[BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) is a library for extracting data from HTML or XML files by accessing concrete elements in the tree structure.\n",
    "The ontology (& the web scraping) is foused on extracting data about PokÃ©mon from a wiki-like website called *[Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Main_Page)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92298eed-c4a4-42c3-baa1-22418e404a0e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87421a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33732f5-8480-4f5f-a8c2-a9b5b52d124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we import the necessary libraries\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7980707-c536-4ede-88ab-3b113df126bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (118297416.py, line 92)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 92\u001b[1;36m\u001b[0m\n\u001b[1;33m    JSON_FILE = \"C:\\Users\\tomma\\Desktop\\Clone Repository Actionable Knowledge\\GameMatcher\\D3\\Scraping\\cleaning\"\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def get_top_100_urls():\n",
    "    list_url = \"https://store.steampowered.com/search/?filter=mostplayed&count=100\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    res = requests.get(list_url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    links = []\n",
    "    rows = soup.find_all('a', class_='search_result_row')\n",
    "    for row in rows[:100]:\n",
    "        links.append(row['href'])\n",
    "    return links\n",
    "\n",
    "def scrape_game_data(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "    # Included age-gate bypass cookies\n",
    "    cookies = {'birthtime': '283996801', 'lastagecheckage': '1-0-1991', 'wants_mature_content': '1'}\n",
    "    \n",
    "    try:\n",
    "        page_res = requests.get(url, headers=headers, cookies=cookies, timeout=10)\n",
    "        gs = BeautifulSoup(page_res.text, 'html.parser')\n",
    "\n",
    "        # --- Name ---\n",
    "        name_tag = gs.find('div', id='appHubAppName') or gs.find('div', class_='apphub_AppName')\n",
    "        NAME = name_tag.get_text(strip=True) if name_tag else \"N/A\"\n",
    "        \n",
    "        # --- Price ---\n",
    "        price_section = gs.find('div', class_='game_purchase_price') or gs.find('div', class_='discount_final_price')\n",
    "        PRICE = price_section.get_text(strip=True) if price_section else \"N/A\"\n",
    "\n",
    "        # --- PEGI ---\n",
    "        pegi_div = gs.find('div', class_='game_rating_icon')\n",
    "        PEGI = pegi_div.find('img').get('alt', 'N/A') if pegi_div and pegi_div.find('img') else \"N/A\"\n",
    "\n",
    "        # --- UPDATED MODE LOGIC (game_area_features_list_ctn) ---\n",
    "        mode_keywords = [\n",
    "            \"Single-player\", \"Multi-player\", \"Online Co-op\", \"LAN Co-op\", \n",
    "            \"Shared/Split Screen Co-op\", \"MMO\", \"Online PvP\", \"LAN PvP\",\n",
    "            \"Cross-Platform Multiplayer\", \"Co-op\", \"PvP\"\n",
    "        ]\n",
    "        \n",
    "        found_modes = []\n",
    "        # Target the specific container you identified\n",
    "        feature_container = gs.find('div', class_='game_area_features_list_ctn')\n",
    "        \n",
    "        if feature_container:\n",
    "            # Find all links within that container\n",
    "            feature_links = feature_container.find_all('a')\n",
    "            for link in feature_links:\n",
    "                # Get the label text (e.g., \"Multi-player\")\n",
    "                label_text = link.find(class_='label').get_text(strip=True) if link.find(class_='label') else link.get_text(strip=True)\n",
    "                \n",
    "                if any(kw.lower() == label_text.lower() or kw.lower() in label_text.lower() for kw in mode_keywords):\n",
    "                    found_modes.append(label_text)\n",
    "\n",
    "        # Remove duplicates and join\n",
    "        MODE = \", \".join(sorted(list(set(found_modes)))) if found_modes else \"Single-player\"\n",
    "\n",
    "        # --- Hardware Helper ---\n",
    "        def get_spec(label):\n",
    "            tag = gs.find('strong', string=re.compile(label, re.IGNORECASE))\n",
    "            if tag:\n",
    "                text = tag.next_sibling\n",
    "                if text and isinstance(text, str):\n",
    "                    return text.strip().strip(':').strip()\n",
    "                return tag.parent.get_text().replace(tag.get_text(), \"\").strip().strip(':').strip()\n",
    "            return \"N/A\"\n",
    "\n",
    "        OS = get_spec(\"OS:\")\n",
    "        CPU = get_spec(\"Processor:\")\n",
    "        RAM = get_spec(\"Memory:\")\n",
    "        GPU = get_spec(\"Graphics:\")\n",
    "        STORAGE = get_spec(\"Storage:\")\n",
    "\n",
    "        return {\n",
    "            \"NAME\": NAME, \"PRICE\": PRICE, \"PEGI\": PEGI, \"MODE\": MODE,\n",
    "            \"OS\": OS, \"CPU\": CPU, \"GPU\": GPU, \"RAM\": RAM, \"STORAGE\": STORAGE\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "JSON_FILE = \"C:\\Users\\tomma\\Desktop\\Clone Repository Actionable Knowledge\\GameMatcher\\D3\\Scraping\\cleaning\\steam_parsed_CLEAN.json\"\n",
    "\n",
    "def update_genres_in_json():\n",
    "    # 1. Load the existing clean data\n",
    "    if not JSON_FILE.exists():\n",
    "        print(f\"Error: {JSON_FILE.name} not found.\")\n",
    "        return\n",
    "\n",
    "    with open(JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        data_list = json.load(f)\n",
    "\n",
    "    # 2. Create a lookup dictionary for fast access: { \"Game Name\": {original_data} }\n",
    "    # We use .get('NAME') to match your scraper's key\n",
    "    lookup = {game.get('NAME'): game for game in data_list}\n",
    "\n",
    "    # 3. Get the URLs to scrape\n",
    "    links = get_top_100_urls()\n",
    "    print(f\"Found {len(links)} games. Starting targeted update...\")\n",
    "\n",
    "    updated_count = 0\n",
    "\n",
    "    for i, link in enumerate(links):\n",
    "        scraped_game = scrape_game_data(link)\n",
    "        \n",
    "        if scraped_game:\n",
    "            name = scraped_game['NAME']\n",
    "            \n",
    "            # 4. Check if this game exists in our file\n",
    "            if name in lookup:\n",
    "                # ONLY update the Genre (and maybe Mode if you want)\n",
    "                lookup[name]['GENRE'] = scraped_game['GENRE']\n",
    "                # lookup[name]['MODE'] = scraped_game['MODE'] # Optional\n",
    "                \n",
    "                print(f\"[{i+1}/100] UPDATED: {name[:30]}\")\n",
    "                updated_count += 1\n",
    "            else:\n",
    "                print(f\"[{i+1}/100] SKIPPED: {name[:30]} (Not in JSON)\")\n",
    "\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    # 5. Save the modified list back to the file\n",
    "    # (lookup.values() turns our dictionary back into a list of objects)\n",
    "    with open(JSON_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(list(lookup.values()), f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nFinished! Updated {updated_count} games in {JSON_FILE.name}.\")\n",
    "\n",
    "# --- RUN ---\n",
    "if __name__ == \"__main__\":\n",
    "    update_genres_in_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bba8a7-4ecf-4f38-8250-cb86590278ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
