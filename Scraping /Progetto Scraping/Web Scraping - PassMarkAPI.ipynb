{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762cf4cb-d833-4c95-a912-c40f004e6fb3",
   "metadata": {},
   "source": [
    "# Solution to Exercise 08 - Web Scraping\n",
    "\n",
    "In today's exercise we're using the Python libraries *BeautifulSoup* and *owlready2* to create an ontology from data scraped from the Web.\n",
    "[BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) is a library for extracting data from HTML or XML files by accessing concrete elements in the tree structure.\n",
    "The ontology (& the web scraping) is foused on extracting data about PokÃ©mon from a wiki-like website called *[Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Main_Page)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92298eed-c4a4-42c3-baa1-22418e404a0e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87421a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\tomma\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: curl_cffi in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from curl_cffi) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from curl_cffi) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tomma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12.0->curl_cffi) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.14.3-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 13.6 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.14.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install webdriver-manager\n",
    "!pip install curl_cffi\n",
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a33732f5-8480-4f5f-a8c2-a9b5b52d124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from curl_cffi import requests\n",
    "from curl_cffi.const import CurlHttpVersion  \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from rapidfuzz import process, fuzz, utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7980707-c536-4ede-88ab-3b113df126bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TechScraper' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 110\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸš€ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mia[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mia[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(diff)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mdiff\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslower\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mib[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mib[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# --- RUN ---\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# 1. CPU Section\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m cpu_tool \u001b[38;5;241m=\u001b[39m \u001b[43mTechScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwww.cpubenchmark.net\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cpu_tool\u001b[38;5;241m.\u001b[39mitems:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cpu_tool\u001b[38;5;241m.\u001b[39mcompare(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi5-8600\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi9-13900K\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m, in \u001b[0;36mTechScraper.__init__\u001b[1;34m(self, domain)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cpu \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load or Scrape\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- No local data found. Starting Scrape for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TechScraper' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from curl_cffi import requests\n",
    "from rapidfuzz import process, fuzz, utils\n",
    "\n",
    "class TechScraper:\n",
    "    def __init__(self, domain=\"www.cpubenchmark.net\"):\n",
    "        self.domain = domain\n",
    "        # Determine if we are looking for CPU or GPU to set page and cache names\n",
    "        self.is_cpu = \"cpu\" in domain\n",
    "        self.mega_page = f\"https://{domain}/CPU_mega_page.html\" if self.is_cpu else f\"https://{domain}/GPU_mega_page.html\"\n",
    "        self.cache_file = \"cpu_data.json\" if self.is_cpu else \"gpu_data.json\"\n",
    "        \n",
    "        # Load or Scrape\n",
    "        self.items = self.load_local()\n",
    "        \n",
    "        if not self.items:\n",
    "            print(f\"--- No local data found. Starting Scrape for {self.domain} ---\")\n",
    "            self.session = requests.Session()\n",
    "            self.items = self.scrape()\n",
    "            if self.items:\n",
    "                self.save_local()\n",
    "\n",
    "    def clean_mark(self, value):\n",
    "        \"\"\"Safely converts benchmark strings to integers, handling 'NA' or 'Insufficient data'.\"\"\"\n",
    "        if value is None:\n",
    "            return 0\n",
    "        \n",
    "        # Convert to string and remove commas\n",
    "        val_str = str(value).replace(',', '').strip()\n",
    "        \n",
    "        # Check if the string is numeric (handles negative signs too)\n",
    "        if val_str.replace('-', '', 1).isdigit():\n",
    "            return int(val_str)\n",
    "        \n",
    "        # If it's \"Insufficient data\", \"NA\", or empty, return 0\n",
    "        return 0\n",
    "\n",
    "    def scrape(self):\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0\",\n",
    "            \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"Referer\": self.mega_page,\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Warming up session for {self.domain}...\")\n",
    "            self.session.get(self.mega_page, impersonate=\"chrome120\")\n",
    "            time.sleep(3)\n",
    "            \n",
    "            print(\"Requesting hardware list...\")\n",
    "            data_url = f\"https://{self.domain}/data/?_={int(time.time()*1000)}\"\n",
    "            response = self.session.get(data_url, headers=headers, impersonate=\"chrome120\", http_version=\"v1\")\n",
    "            \n",
    "            data = response.json().get(\"data\", [])\n",
    "            if not data:\n",
    "                print(\"âŒ Server returned empty list.\")\n",
    "                return []\n",
    "            print(data[0])\n",
    "            print(f\"âœ… Success! Found {len(data)} items.\")\n",
    "            \n",
    "            mark_key = 'cpumark' if self.is_cpu else 'g3dmark'\n",
    "            \n",
    "            # Use the new clean_mark function here\n",
    "            return [\n",
    "                {\n",
    "                    \"name\": x.get('name'), \n",
    "                    \"mark\": self.clean_mark(x.get(mark_key)), \n",
    "                    \"rank\": self.clean_mark(x.get('rank'))\n",
    "                } \n",
    "                for x in data\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Scrape failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def save_local(self):\n",
    "        with open(self.cache_file, 'w') as f:\n",
    "            json.dump(self.items, f)\n",
    "        print(f\"ðŸ’¾ Data saved to {self.cache_file}.\")\n",
    "\n",
    "    def load_local(self):\n",
    "        try:\n",
    "            with open(self.cache_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                print(f\"ðŸ“‚ Loaded {len(data)} items from {self.cache_file}.\")\n",
    "                return data\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def get_best_match(self, query):\n",
    "        if not self.items: return None\n",
    "        names = [i['name'] for i in self.items]\n",
    "        res = process.extractOne(query, names, scorer=fuzz.token_set_ratio, processor=utils.default_process)\n",
    "        return next(i for i in self.items if i['name'] == res[0]) if res and res[1] > 60 else None\n",
    "\n",
    "    def compare(self, a, b):\n",
    "        ia, ib = self.get_best_match(a), self.get_best_match(b)\n",
    "        if not ia or not ib: return \"âŒ Model not found.\"\n",
    "        diff = ((ia['mark'] - ib['mark']) / ib['mark']) * 100\n",
    "        label = \"CPU Mark\" if self.is_cpu else \"G3D Mark\"\n",
    "        return f\"\\nðŸš€ {ia['name']} ({label}: {ia['mark']}) is {abs(diff):.1f}% {'faster' if diff > 0 else 'slower'} than {ib['name']} ({ib['mark']}).\"\n",
    "\n",
    "# --- RUN ---\n",
    "\n",
    "# 1. CPU Section\n",
    "cpu_tool = TechScraper(\"www.cpubenchmark.net\")\n",
    "if cpu_tool.items:\n",
    "    print(cpu_tool.compare(\"i5-8600\", \"i9-13900K\"))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. GPU Section\n",
    "gpu_tool = TechScraper(\"www.videocardbenchmark.net\")\n",
    "if gpu_tool.items:\n",
    "    print(gpu_tool.compare(\"RTX 3060\", \"RTX 4090\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
